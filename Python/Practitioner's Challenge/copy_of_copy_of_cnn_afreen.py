# -*- coding: utf-8 -*-
"""Copy of Copy of CNN_Afreen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FI8lKxwu9nJrD3pfT1ax1SYxOfse5gWL
"""

"""
This is a sample detector that serves as a placeholder for 
your awesome sophisticated ML detector.
"""

from obspy.core import Trace, UTCDateTime
from obspy.signal.trigger import recursive_sta_lta, trigger_onset
import numpy as np
from scipy import signal
import pandas as pd
from scipy.fftpack import dct
from keras.models import load_model
import tensorflow as tf
from sklearn.model_selection import train_test_split

def testing(self,X_train):
  rolling_window_index_a,rolling_window_index_b,rolling_window_index_c = rolling_window_index()
  window_A = get_windowA(rolling_window_index_a,X_train)
  #modelA(window_A,windowA_target(total_index,rolling_window_index_a)) # Fitting Model for window A
  ts_ix,chosen_index_a,pred_label = windowA_pred(window_A)  # need to check this
  window_B,a_ix = get_windowB(ts_ix,chosen_index_a,pred_label,window_A,rolling_window_index_b,window_A)
  #modelB(window_B,windowB_target(ts_ix,chosen_ix_train,total_index,a_ix,rolling_window_index_b)) # Need to check this
  b_ix = windowB_pred(window_B)
  window_C = get_windowC(b_ix,window_B,rolling_window_index_c)
  #model_picker(window_C,windowC_target(ts_ix,chosen_ix_train,total_index,a_ix,b_ix,rolling_window_index_c))
  c_ix = windowC_pred(window_C) # Need to Check
  predictions = final_pred(pred_label,a_ix,b_ix,c_ix,rolling_window_index_c,X_train)
  return predictions


def rolling_window_index():
  rolling_window_index_a = []
  window_size = 90
  for a in range(0,1000-window_size,4):
      rolling_window_index_a.append((a,a+window_size))
  rolling_window_index_a = np.array(rolling_window_index_a)
  rolling_window_index_b = []
  window_size=50
  for wind_ix in rolling_window_index_a:
        wind_a_b = []
        for b in range(wind_ix[0],wind_ix[1]-window_size,4):
            wind_a_b.append((b,b+window_size))
        rolling_window_index_b.append(wind_a_b)
  rolling_window_index_b = np.array(rolling_window_index_b)
  rolling_window_index_c = []
  window_size=25
  for ix , b in enumerate(rolling_window_index_b):
      wind_a_b_c = []
      for wind_ix_b in b:
          wind_a_b = []
          for c in range(wind_ix_b[0],wind_ix_b[1]-window_size,4):
              wind_a_b.append((c,c+window_size))
          wind_a_b_c.append(wind_a_b)
      rolling_window_index_c.append(wind_a_b_c)
  rolling_window_index_c = np.array(rolling_window_index_c)
  return (rolling_window_index_a,rolling_window_index_b,rolling_window_index_c)
	
def get_windowA(rolling_window_index_a,tr):
  window_A = []
  for win_ix in rolling_window_index_a:
      original = tr.data[win_ix[0]:win_ix[1]]
      freq_domain = dct(original)
      original_scaled = tr.normalize().data[win_ix[0]:win_ix[1]]
      freq_scaled = (freq_domain - np.mean(freq_domain, axis=0)) / np.std(freq_domain, axis=0)
      window_A.append(np.concatenate([original_scaled,dct(freq_scaled)]))
  window_A = np.array(window_A)
  window_A = window_A.reshape(-1,228,90,2)
  return window_A

def windowA_pred(X_test,model):
  pred = model.predict(X_test)
  threshold = 0.7 # after smote will work better
  pred_label = []
  chosen_index_a = []
  for ix,pred_wind in enumerate(pred):
      print(max(pred_wind))
      if max(pred_wind)>threshold: # for futrue improvement, get the total vote count for pwave
          pred_label.append(1)
          chosen_index_a.append(np.where(pred_wind == np.amax(pred_wind))[0][0])
      else:
          pred_label.append(0)
          chosen_index_a.append(None)
  pred_label = np.array(pred_label)
  chosen_index_a = np.array(chosen_index_a)
  return (chosen_index_a,pred_label)
	
def get_windowB(chosen_index_a,rolling_window_index_b,window_A):
  # chosen_index_a.shape = (1,)
  # pred_label.shape = (1,)
  window_B = []
  a_ix = chosen_index_a[0] # out of 225 windows
  chosen_wind_a = window_A[0,a_ix,:,0] # take only the time domain
  for win_ix in rolling_window_index_b[0,:,:]:
      original = chosen_wind_a[win_ix[0]:win_ix[1]]
      freq_domain = dct(original)
      original_scaled = (original - np.mean(original, axis=0)) / np.std(original, axis=0)
      freq_scaled = (freq_domain - np.mean(freq_domain, axis=0)) / np.std(freq_domain, axis=0)
      window_B.append(np.concatenate([original_scaled,dct(freq_scaled)]))
  window_B = np.array(window_B)
  window_B = window_B.reshape(-1,10,50,2)
  return (window_B,a_ix)

def windowB_pred(X_test,model):
  pred_b = model.predict(X_test)
  b_ix = []
  for ix,pred_wind in enumerate(pred_b):
      b_ix.append(np.where(pred_wind == np.amax(pred_wind))[0][0])
  b_ix = np.array(b_ix)  
  return b_ix
	

def get_windowC(b_ix,row,rolling_window_index_c):
  window_C = []
  chosen_wind_b = row[0,b_ix[0],:,0]
  for win_ix in rolling_window_index_c[0,0,:,:]: # Check this
      original = chosen_wind_b[win_ix[0]:win_ix[1]]
      freq_domain = dct(original)
      original_scaled = (original - np.mean(original, axis=0)) / np.std(original, axis=0)
      freq_scaled = (freq_domain - np.mean(freq_domain, axis=0)) / np.std(freq_domain, axis=0)
      window_C.append(np.concatenate([original_scaled,dct(freq_scaled)]))
  window_C = np.array(window_C)
  window_C = window_C.reshape(-1,7,25,2)
  return window_C


def windowC_pred(X_test,model):
  pred_c = model.predict(X_test)
  c_ix = []
  for ix,pred_wind in enumerate(pred_c):
      c_ix.append(np.where(pred_wind == np.amax(pred_wind))[0][0])
  c_ix = np.array(c_ix)
  return c_ix

	
def final_pred(pred_label,a_ix,b_ix,c_ix,rolling_window_index_c,total_raw_data):
  prediction = []
  ticker = 0
  for ix, x in enumerate(pred_label):
      if x==1:
        prediction.append(rolling_window_index_c[a_ix[ticker,],b_ix[ticker,],c_ix[ticker,],0])
        ticker += 1
      else:
        prediction.append(None)

  for ix , idx in enumerate(chosen_ix_train):
      starttime = total_raw_data[idx].stats.starttime
      freq = total_raw_data[idx].stats.sampling_rate
      if prediction[ix] is None:
          continue
      else:
          prediction[ix] = starttime + prediction[ix]/freq

  prediction = np.array(prediction)
  return prediction


def predict(tr,modelA,modelB,model_picker): # define model seperately to avoid tf retracting (super slow)

  rolling_window_index_a,rolling_window_index_b,rolling_window_index_c = rolling_window_index()
  window_A = get_windowA(rolling_window_index_a,tr)
  chosen_index_a,pred_label = windowA_pred(window_A,modelA)  # need to check this
  if pred_label[0] == 0:
    return None
  window_B,a_ix = get_windowB(chosen_index_a,rolling_window_index_b,window_A)
  b_ix = windowB_pred(window_B,modelB)
  window_C = get_windowC(b_ix,window_B,rolling_window_index_c)
  c_ix = windowC_pred(window_C,model_picker) # Need to Check


  pred_index = int((rolling_window_index_c[a_ix,b_ix,c_ix,0][0]+rolling_window_index_c[a_ix,b_ix,c_ix,1][0])/2)
  prediction = tr.stats.starttime + pred_index/tr.stats.sampling_rate

  return prediction

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
import os
os.chdir("/content/drive/MyDrive/Colab Notebooks/Practitioner's Challenge")

!pip install obspy
!pip install numpy==1.20.0

os.getcwd()

# import sys
# sys.path.append("/content/drive/My Drive/Colab Notebooks/Practitioner's Challenge")

import pandas as pd
import numpy as np
from os import listdir
from os.path import isfile, join
from obspy import read
from tqdm import tqdm
from joblib import Parallel, delayed
import warnings
import dask as dd
import random
from scipy.fftpack import dct
from sklearn.model_selection import train_test_split
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from keras.models import load_model
import keras as ks
from keras.layers import Input, Dense,  LSTM, Flatten
import gc
import pandas as pd
import tensorflow as tf
from models.utils import focal_loss
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score,roc_curve
from sklearn.utils import shuffle
from keras import backend as K
from sklearn.metrics import f1_score
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling1D, Flatten, Dropout, Dense,Conv1D

"""# Reading Files"""

def identify_files_in_directory(path):
  """
  Identifing all files in the given directory

  :param path: String, the path
  :return: list, list of all objects in the given path
  """
  return [f for f in listdir(path) if isfile(join(path, f))]

signal_paths = identify_files_in_directory("./data/signal")
noise_paths = identify_files_in_directory("./data/noise")

def read_data_from_disk(path, files):
  """
  This functions aims to read all the given data from the files list into memory

  :param files: string, the path towards the data
  :param files: list, list of objects to read in
  :return: Array containing the data
  """

  # set variables
  random.seed(0)
  p_win = (.5, 3) # setting limits for P-wave 
  sampling_rate = 31.25
  min_snr = 1.5

  all_raw_data = []
  all_correct_answer = []
  pwave_index = []
  for i in tqdm(files):
      st = read(f'{path}/{i}')
      # cut = int((random.random()*1000)) # change to [0,1000]
      cut = int((random.random()*p_win[1]+p_win[0])*sampling_rate)

      for tr in st:
        snr = sum(abs(tr.data[1000:1032]))/sum(abs(tr.data[1000-32:1000]))
        if "_P" in i and snr<=min_snr:
          print("  Channel: {}, passing, not high-enough P wave S/N ratio ({:4.2f})".format(tr.stats.channel, snr))      
        
        # otherwise do everything
        else:
            tr.data = tr.data[cut:1000+cut]
            all_raw_data.append(tr)
            # set correct answers
            if "_N" in i:
                # if it is a noise segment, the correct answer is None
                correct_answer = None
                pwave_ix = None
            else:
                # if it is a p-wave segment, the correct answer is the p-wave arrival time (UTCDateTime format)
                correct_answer = tr.stats.starttime + (1000-cut)/tr.stats.sampling_rate
                pwave_ix = int(1000-cut)
            all_correct_answer.append(correct_answer)
            pwave_index.append(pwave_ix)

      del st
  all_correct_answer = np.array(all_correct_answer)
  return all_raw_data, all_correct_answer, pwave_index

short_noise_paths = noise_paths[9000:10000]
short_signal_paths = signal_paths

raw_data_signal, signal_target, signal_index= read_data_from_disk("./data/signal",short_signal_paths)
raw_data_noise, noise_target, noise_index = read_data_from_disk("./data/noise",short_noise_paths)

total_raw_data = raw_data_noise+raw_data_signal

total_index = noise_index+signal_index

y = np.concatenate((noise_target,signal_target),axis=0)

y_class = [int(1) if tar is not None else int(0) for tar in y  ]

index_ts = np.array(range(np.array(total_raw_data).shape[0]))

"""# Training Model"""

def rolling_window_index():
    rolling_window_index_a = []
    window_size = 90
    for a in range(0,1000-window_size,3):
        rolling_window_index_a.append((a,a+window_size))
    rolling_window_index_a = np.array(rolling_window_index_a)
    rolling_window_index_b = []
    window_size=45
    for wind_ix in rolling_window_index_a:
         wind_a_b = []
         for b in range(wind_ix[0],wind_ix[1]-window_size,3):
             wind_a_b.append((b,b+window_size))
         rolling_window_index_b.append(wind_a_b)
    rolling_window_index_b = np.array(rolling_window_index_b)
    rolling_window_index_c = []
    window_size=25
    for ix , b in enumerate(rolling_window_index_b):
        wind_a_b_c = []
        for wind_ix_b in b:
            wind_a_b = []
            for c in range(wind_ix_b[0],wind_ix_b[1]-window_size,3):
                wind_a_b.append((c,c+window_size))
            wind_a_b_c.append(wind_a_b)
        rolling_window_index_c.append(wind_a_b_c)
    rolling_window_index_c = np.array(rolling_window_index_c)
    return (rolling_window_index_a,rolling_window_index_b,rolling_window_index_c)

def get_f1(y_true, y_pred): #taken from old keras source code
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    recall = true_positives / (possible_positives + K.epsilon())
    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
    return f1_val

def modelA(X_train,y_train):
    model = Sequential()
    model.add(Conv2D(20,kernel_size = (20,2),activation = 'relu',padding = 'same', input_shape = (304,90,2)))
    model.add(Dropout(0.2))
    model.add(Conv2D(10,kernel_size = (30,1),activation = 'relu',padding = 'same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(200,activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(304,activation = 'sigmoid'))
    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),optimizer='adam',metrics=["accuracy"])
    callback = EarlyStopping(monitor='loss', patience=5)
    model.fit(X_train,y_train,epochs = 10, shuffle = True, callbacks = [callback],validation_split = 0.1)
    model.save("modelA.h5")

def modelB(X_train,y_train):
 
    model = Sequential()
    model.add(Conv2D(20,kernel_size = (5,2),activation = 'relu',padding = 'same', input_shape = (15,45,2)))
    model.add(Dropout(0.2))
    model.add(Conv2D(10,kernel_size = (10,1),activation = 'relu',padding = 'same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(200,activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(15,activation = 'sigmoid'))  # Add number of windows
    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),optimizer='adam',metrics=["accuracy"])
    callback = EarlyStopping(monitor='loss', patience=5)
    model.fit(X_train,y_train,epochs = 10, shuffle = True, callbacks = [callback],validation_split = 0.1)
    model.save("modelB.h5")

def model_picker(X_train,y_train):
    model = Sequential()
    model.add(Conv2D(20,kernel_size = (3,2),activation = 'relu',padding = 'same', input_shape = (7,25,2)))
    model.add(Dropout(0.2))
    model.add(Conv2D(10,kernel_size = (5,1),activation = 'relu',padding = 'same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(200,activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(7,activation = 'sigmoid'))  # Add 
    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),optimizer='adam',metrics=["accuracy"])
    callback = EarlyStopping(monitor='loss', patience=5)
    model.fit(X_train,y_train,epochs = 10, shuffle = True, callbacks = [callback],validation_split = 0.1)
    model.save("model_picker.h5")

def get_windowA(rolling_window_index_a,total_raw_data):
    window_A = []
    for tr in total_raw_data:
        ts_win_a = []
        for win_ix in rolling_window_index_a:
            original = tr.data[win_ix[0]:win_ix[1]]
            freq_domain = dct(original)
            original_scaled = tr.normalize().data[win_ix[0]:win_ix[1]]
            freq_scaled = (freq_domain - np.mean(freq_domain, axis=0)) / np.std(freq_domain, axis=0)
            ts_win_a.append(np.concatenate([original_scaled,dct(freq_scaled)]))
        window_A.append(ts_win_a)
    window_A = np.array(window_A)
    window_A = window_A.reshape(-1,304,90,2)
    return window_A

def windowA_target(total_index,rolling_window_index_a):
    y_train_window_bool = []
    for ix in total_index:
         if ix is None:
             y_train_window_bool.append(np.zeros((304)))
         else:
              y_train_window_bool.append(np.array([1 if ix>wind_ix[0] and ix<wind_ix[1] else 0 for wind_ix in rolling_window_index_a]))
    y_train_window_bool = np.array(y_train_window_bool)
    return y_train_window_bool

def windowA_pred(total_raw_data):

    model = tf.keras.models.load_model('modelA.h5')
    pred = model.predict(total_raw_data)
    threshold = 0.7 # after smote will work better
    pred_label = []
    chosen_index_a = []
    ts_ix = []
    for ix,pred_wind in enumerate(pred):
        if max(pred_wind)>threshold: # for futrue improvement, get the total vote count for pwave
            pred_label.append(1)
            chosen_index_a.append(np.where(pred_wind == np.amax(pred_wind))[0][0])
            ts_ix.append(ix)
        else:
            pred_label.append(0)
            chosen_index_a.append(None)
    pred_label = np.array(pred_label)
    chosen_index_a = np.array(chosen_index_a)
    ts_ix = np.array(ts_ix)
    return (ts_ix,chosen_index_a,pred_label)

def get_windowB(ts_ix,chosen_index_a,pred_label,X_train,rolling_window_index_b,window_A):
    window_B = []
    a_ix = chosen_index_a[pred_label==1] # out of 225 windows
    for ix, tr in enumerate(X_train[pred_label==1]):
        ts_win_b = []
        chosen_wind_a = window_A[ts_ix[ix],a_ix[ix],:,0] # take only the time domain
        for win_ix in rolling_window_index_b[0,:,:]:
            original = chosen_wind_a[win_ix[0]:win_ix[1]]
            freq_domain = dct(original)
            original_scaled = (original - np.mean(original, axis=0)) / np.std(original, axis=0)
            freq_scaled = (freq_domain - np.mean(freq_domain, axis=0)) / np.std(freq_domain, axis=0)
            ts_win_b.append(np.concatenate([original_scaled,dct(freq_scaled)]))  
        window_B.append(ts_win_b)
    window_B = np.array(window_B)
    window_B = window_B.reshape(-1,15,45,2)
    return (window_B,a_ix)

def windowB_target(ts_ix,chosen_ix_train,total_index,a_ix,rolling_window_index_b):
    y_train_window_b_bool = []
    for count, row in enumerate(ts_ix):
        row_bool = []
        pwave_index = total_index[chosen_ix_train[row]]
        if pwave_index is None:
           y_train_window_b_bool.append(np.zeros(15))
        else:
             y_train_window_b_bool.append(np.array([1 if pwave_index>wind_ix[0] and pwave_index<wind_ix[1] else 0 for wind_ix in rolling_window_index_b[a_ix[count]]]))
    y_train_window_b_bool = np.array(y_train_window_b_bool)
    return y_train_window_b_bool

def windowB_pred(X_test):

    model = tf.keras.models.load_model('modelB.h5')  
    pred_b = model.predict(X_test)
    b_ix = []
    for ix,pred_wind in enumerate(pred_b):
        b_ix.append(np.where(pred_wind == np.amax(pred_wind))[0][0])
    b_ix = np.array(b_ix)  
    return b_ix

def get_windowC(b_ix,window_B,rolling_window_index_c):
    window_C = []
    for ix, row in enumerate(window_B):
        ts_win_c = []
        chosen_wind_b = row[b_ix[ix],:,0]
        for win_ix in rolling_window_index_c[0,0,:,:]: # Check this
            original = chosen_wind_b[win_ix[0]:win_ix[1]]
            freq_domain = dct(original)
            original_scaled = (original - np.mean(original, axis=0)) / np.std(original, axis=0)
            freq_scaled = (freq_domain - np.mean(freq_domain, axis=0)) / np.std(freq_domain, axis=0)
            ts_win_c.append(np.concatenate([original_scaled,dct(freq_scaled)]))  
        window_C.append(ts_win_c)
    window_C = np.array(window_C)
    window_C = window_C.reshape(-1,7,25,2)
    return window_C

def windowC_target(ts_ix,chosen_ix_train,total_index,a_ix,b_ix,rolling_window_index_c):
    y_train_window_c_bool = []
    for count, row in enumerate(ts_ix):
        row_bool = []
        pwave_index = total_index[chosen_ix_train[row]]
        if pwave_index is None:
           y_train_window_c_bool.append(np.zeros(7))
        else:
             y_train_window_c_bool.append(np.array([1 if pwave_index>wind_ix[0] and pwave_index<wind_ix[1] else 0 for wind_ix in rolling_window_index_c[a_ix[count],b_ix[count]]]))
    y_train_window_c_bool = np.array(y_train_window_c_bool)
    return y_train_window_c_bool

def windowC_pred(X_test):
    model = tf.keras.models.load_model('model_picker.h5')
    pred_c = model.predict(X_test)
    c_ix = []
    for ix,pred_wind in enumerate(pred_c):
        c_ix.append(np.where(pred_wind == np.amax(pred_wind))[0][0])
    c_ix = np.array(c_ix)
    return c_ix

def final_pred(pred_label,a_ix,b_ix,c_ix,rolling_window_index_c,total_raw_data,chosen_ix_train):
    prediction = []
    ticker = 0
    for ix, x in enumerate(pred_label):
        if x==1:
          prediction.append(rolling_window_index_c[a_ix[ticker,],b_ix[ticker,],c_ix[ticker,],0])
          ticker += 1
        else:
          prediction.append(None)

    for ix , idx in enumerate(chosen_ix_train):
        starttime = total_raw_data[idx].stats.starttime #
        freq = total_raw_data[idx].stats.sampling_rate
        if prediction[ix] is None:
           continue
        else:
            prediction[ix] = starttime + prediction[ix]/freq

    prediction = np.array(prediction)
    return prediction

def training(total_raw_data,total_index,chosen_ix_train):
    rolling_window_index_a,rolling_window_index_b,rolling_window_index_c = rolling_window_index()
    window_A = get_windowA(rolling_window_index_a,total_raw_data)
    modelA(window_A,windowA_target(total_index,rolling_window_index_a)) # Fitting Model for window A
    ts_ix,chosen_index_a,pred_label = windowA_pred(window_A)  # need to check this
    window_B,a_ix = get_windowB(ts_ix,chosen_index_a,pred_label,window_A,rolling_window_index_b,window_A)
    print(window_B.dtype)
    del window_A
    # window_B = tf.convert_to_tensor(window_B)
    modelB(window_B,windowB_target(ts_ix,chosen_ix_train,total_index,a_ix,rolling_window_index_b)) # Need to check this
    b_ix = windowB_pred(window_B)
    window_C = get_windowC(b_ix,window_B,rolling_window_index_c)
    del window_B
    model_picker(window_C,windowC_target(ts_ix,chosen_ix_train,total_index,a_ix,b_ix,rolling_window_index_c))
    c_ix = windowC_pred(window_C) # Need to Check
    predictions = final_pred(pred_label,a_ix,b_ix,c_ix,rolling_window_index_c,total_raw_data,chosen_ix_train)
    return predictions

# rolling_window_index_a,rolling_window_index_b,rolling_window_index_c = rolling_window_index()
# window_A = get_windowA(rolling_window_index_a,total_raw_data)
# modelA(window_A,windowA_target(total_index,rolling_window_index_a)) # Fitting Model for window A
# ts_ix,chosen_index_a,pred_label = windowA_pred(window_A)  # need to check this
# window_B,a_ix = get_windowB(ts_ix,chosen_index_a,pred_label,window_A,rolling_window_index_b,window_A)
# print(window_B.dtype)

# windowB_target(ts_ix,index_ts,total_index,a_ix,rolling_window_index_b)



pred = training(total_raw_data,total_index,index_ts)

len(pred)

pred_1 = [1 if i != None else 0 for i in total_index]
pred_2 = [1 if i != None else 0 for i in pred]

from sklearn.metrics import accuracy_score,f1_score
print(accuracy_score(pred_1,pred_2),f1_score(pred_1,pred_2))

"""# Testing on New Data"""

short_noise_paths_X = noise_paths[9102:10202]
short_signal_paths_X = signal_paths[1102:1222]

raw_data_signal_test, signal_target_test, signal_index_test = read_data_from_disk("./data/signal",short_signal_paths_X)
raw_data_noise_test, noise_target_test, noise_index_test = read_data_from_disk("./data/noise",short_noise_paths_X)

total_raw_data_test = raw_data_noise_test + raw_data_signal_test

total_index_test = noise_index_test + signal_index_test

index_ts_test = np.array(range(np.array(total_raw_data_test).shape[0]))

def testing(total_raw_data,total_index,chosen_ix_train):
    rolling_window_index_a,rolling_window_index_b,rolling_window_index_c = rolling_window_index()
    window_A = get_windowA(rolling_window_index_a,total_raw_data)
    ts_ix,chosen_index_a,pred_label = windowA_pred(window_A)  # need to check this
    window_B,a_ix = get_windowB(ts_ix,chosen_index_a,pred_label,window_A,rolling_window_index_b,window_A)
    b_ix = windowB_pred(window_B)
    window_C = get_windowC(b_ix,window_B,rolling_window_index_c)
    c_ix = windowC_pred(window_C) # Need to Check
    predictions = final_pred(pred_label,a_ix,b_ix,c_ix,rolling_window_index_c,total_raw_data,chosen_ix_train)
    return predictions

predictions = testing(total_raw_data_test,total_index_test,index_ts_test)

pred_1 = [1 if i != None else 0 for i in total_index_test]
pred_2 = [1 if i != None else 0 for i in predictions]

from sklearn.metrics import accuracy_score,f1_score
print(accuracy_score(pred_1,pred_2),f1_score(pred_1,pred_2))

len(pred)

len(predictions)

